\documentclass[12pt,a4paper,openright,twoside]{book}
\usepackage[utf8]{inputenc}
\usepackage{disi-thesis}
\usepackage{code-lstlistings}
\usepackage{notes}
\usepackage{shortcuts}
\usepackage{acronym}
\usepackage[acronym]{glossaries}
\usepackage{float}
\usepackage{url}
\def\UrlBreaks{\do\/\do-\do\&\do.\do:}

\school{\unibo}
\programme{Corso di Laurea Triennale in Ingegneria e Scienze Informatiche}
\title{Uso del Machine Learning per la detection dei domini DGA \break (Domain Generation Algorithm)}
\author{Simone Collorà}
\date{\today}
\subject{Programmazione a Oggetti}
\supervisor{Prof. Mirko Viroli}
%\cosupervisor{Dott. Gianluca Aguzzi}
%\morecosupervisor{Dott. CoSupervisor 2}
\session{I}
\academicyear{2024-2025}

% Definition of acronyms
\acrodef{IoT}{Internet of Thing}
\acrodef{vm}[VM]{Virtual Machine}
\newacronym{DGA}{DGA}{Domain Generation Algorithm}
\newacronym{C&C}{C\&C}{Command and Control}
\newacronym{P2P}{P2P}{Peer to Peer}
\newacronym{IRC}{IRC}{Internet Relay Chat}


\mainlinespacing{1.05} % line spacing in mainmatter, comment to default (1) before it was 1.241

\begin{document}
\frontmatter\frontispiece
\nocite{*}

\begin{abstract}	
%Max 2000 characters, strict.
I Domain Generation Algorithms (DGA) sono algoritmi che generano domini in modo pseudo casuale.
Questi domini vengono utilizzati dai malware per comunicare con i loro server,
i Command and Control servers (C\&C).
I DGA sono stati sviluppati per superare le limitazioni
dei metodi precedenti come i domini hard-coded, i quali
sono prevedibili e facilmente bloccabili.
I domini DGA, invece, sono quasi impossibili da prevedere e da bloccare con i metodi tradizionali,
come le blacklist,
poiché, i domini generati, sono migliaia e pseudo casuali.
Lo scopo di questo progetto di tesi è quello di analizzare
e sviluppare soluzioni per la rilevazione dei domini DGA attraverso il Machine Learning, cercando
di creare un modello in grado di rilevarli e distinguerli
dai domini legit.
Sono stati analizzati e sperimentati quattro algoritmi di Machine Learning
per la rilevazione dei domini DGA, due algoritmi classici 
basati su tecniche di feature extraction, ovvero le caratteristiche estratte dai dati(i domini nel nostro caso),
e due basati su tecniche di Deep Learning, che quindi impiegano delle
reti neurali capaci di imparare direttamente dai dati.
I due algoritmi di Machine Learning basati su feature extraction
sono il Random Forest e l'XGBoost, mentre i due algortimi
di Deep Learning sono la Long Short-Term Memory (LSTM) e la Bidirectional LSTM.
I modelli sono stati addestrati e testati su un dataset di domini
DGA e legit diviso in training, validation e test set.
I risultati sono basati su diverse metriche e
sono stati confrontati tra i vari modelli.
I modelli con risultati migliori sono stati
quelli basati su deep learning con un'accuretezza del 99\% e una differenza di accuratezza del 7\%
circa rispetto agli altri modelli,
mentre, quelli più performanti in termini di tempo,
sono stati quelli basati su feature extraction
impiegando più di 30 volte in meno rispetto ai modelli di deep learning.
\end{abstract}



%----------------------------------------------------------------------------------------
\tableofcontents   
\listoffigures     % (optional) comment if empty
%\lstlistoflistings  (optional) comment if empty
%----------------------------------------------------------------------------------------

\mainmatter

%----------------------------------------------------------------------------------------
\chapter{Introduzione}
\label{chap:introduction}
%----------------------------------------------------------------------------------------

La sicurezza informatica è un argomento di crescente importanza
nel mondo moderno. Con il passare del tempo,
i sistemi di protezione sono diventati sempre più sofisticati
e potenti ma, allo stesso tempo, anche gli hackers 
hanno sviluppato tecniche sempre più avanzate per eludere i sistemi di protezione.
Tra queste vi è sicuramente l'uso di Botnets e
dei Command and Control(C\&C) servers. I C\&C sono dei server che manipolano una rete
di computer infetti da malwares, chiamati Botnets, permettendo
all'attaccante di eseguire codice malevolo da remoto.
Il malware, però, deve conoscere un indirizzo IP o un dominio
per contattare il server. L'attaccante potrebbe
inserire in modo hard-coded l'indirizzo IP del server nel codice del malware,
ma questo metodo è facilmente rilevabile e bloccabile.
Gli hackers, quindi, preferiscono utilizzare dei domini
generati in modo pseudo casuale da degli algoritmi per nascondere i loro server chiamati
Domain Generation Algorithms(o DGA).
Questi algoritmi generano migliaia di domini al giorno
che vengono poi utilizzati dai malware per contattare i server C\&C,
rendendo difficile per i sistemi di protezione bloccarli
poiché appena un dominio viene bloccato, il malware passa semplicemente al prossimo dominio generato.
I metodi tradizionali per bloccare i domini malevoli come le blacklist,
risultano inefficaci per i DGA poiché i domini generati sono troppi
ed è molto difficile e dispendioso risalire al seed usato per generare i domini
tramite reverse engineering.
Perciò, negli ultimi anni, sono stati sviluppati vari metodi di Machine Learning
capaci di rilevare e bloccare i DGA in modo più efficace. \vfill
\paragraph{Struttura della tesi}
La tesi si dividerà in 3 capitoli. Nel primo
capitolo verrano descritti concetti di base riguardanti Domini e DNS, DGA e Botnets
e Machine Learning con una breve descrizione delle reti neurali e degli
algoritmi utilizzati. Nel secondo capitolo verrà descritto il progetto,
i suoi obiettivi e i risultati ottenuti. Nell'ultimo capitolo
verranno discusse le conclusioni e i possibili sviluppi futuri.

%\note{At the end, describe the structure of the paper}

\chapter{Background}

Di seguito sono descritti i concetti base su cui si basa il progetto.

\section{Domini e Domain Name System}
Un \textbf{dominio} è un nome univoco che identifica un sito web.
I domini sono composti da due parti principali, il nome e l'estenzione del dominio.
Il nome del dominio è la parte principale che identifica il sito web
ad esempio \texttt{google} in \texttt{google.com}.
L'estensione del dominio, invece, è la parte finale
che identifica la provenienza del sito o lo scopo. Degli esempi possono essere
\texttt{.com}, il più usato, per i siti commerciali,
\texttt{.it} per i siti italiani, \texttt{.org} per le organizzazioni.
Un dominio può essere registrato da chiunque tramite
un \textbf{registrar}, ovvero
un'azienda che gestisce la registrazione dei domini.
Il dominio sarà unico e non potrà essere registrato da nessun altro
fino a quando esso non verrà rimosso o scadrà.
Un dominio può essere registrato per un periodo di tempo
che va da un minimo di un anno a un massimo di dieci anni.
Un dominio può essere composto da lettere, numeri e trattini
ma non può iniziare o finire con un trattino.
Un dominio può essere composto da un massimo di 63 caratteri
e non può contenere spazi o caratteri speciali e 
può essere diviso in sottodomini, che sono
parte del dominio principale e sono separati da un punto.
Un esempio di sottodominio può essere \texttt{translate.google.com} in cui
\texttt{translate} è il sottodominio di \texttt{google.com} per Google Translate.
Il dominio solo però non basta per raggiungere un sito web.
È necessario conoscere l'indirizzo IP
del server che ospita il sito web. 
Questo problema viene risolto dal Domain Name System. \hfill \break
Il \textbf{Domain Name System} (più spesso abbreviato DNS)
è un sistema che traduce i nomi di dominio in indirizzi IP.
Quando un utente inserisce un dominio nel browser, il DNS
cerca l'indirizzo IP associato a quel dominio
e lo restituisce al browser che poi si connetterà al sito web desiderato. \raggedbottom

\section{Botnets e DGA}
\subsection{Botnets}
I \textbf{Botnets} sono reti di computer infetti da malware, chiamati bot,
che possono essere controllati da uno o più hackers, chiamati \textbf{botmaster}.
La vita di un botnet nella maggior parte dei casi è divisa in 4 fasi:
\begin{enumerate}
    \item \textbf{Infezione e propagazione}: Questo è il primo
    passaggio. L'hacker cerca di infettare un computer
    tramite vari metodi come email con link malevoli o Peer-to-peer(P2P) sharing.
    Una volta infettato un dispositivo, il malware cerca di infettare
    altri dispositivi nella rete.

    \item \textbf{Rallying}: i bots cercano di contattare per la prima volta
    il server Command and Control(C\&C) per far capire all'hacker
    che l'attacco è andato a buon fine.

    \item \textbf{Commands and Reports}: il malware esegue le istruzioni
    ricevute dal server C\&C e invia i risultati al botmaster.
    I bots ascoltano continuamente il server C\&C 
    o si connettono ad esso periodicamente. Appena ricevono
    un comando lo eseguono, inviano i risultati al botmaster
    e aspettano un nuovo comando.

    \item \textbf{Abbandono}: Quando un bot non è più utile o utilizzabile,
    il botmaster può decidere di abbandonarlo. Il botnet, invece,
    sarà completamente distrutto quando tutti i bot saranno
    abbandonati o bloccati dalla vittima o quando il C\&C server
    verrà bloccato


\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/The-Lifecycle-Schema-of-a-typical-Botnet.png}
    \caption{Ciclo di vita di un botnet \cite{Ogu2016}}
    \label{fig:botnet}
\end{figure}

\subsection{Command and Control} 

Il meccanismo del Command and Control, spesso abbreviato in C\&C, crea un canale di comunicazione
tra il botmaster e i bot. Questo è essenziale per il funzionamento
del botnet. Ci sono tre tipi di server C\&C:

\begin{itemize}
    \item \textbf{Centralizzati}: In questo tipo di server, il botmaster
    controlla tutti i bot tramite un server centrale. Questo è il metodo
    più semplice e veloce per controllare i bot ma è anche il più vulnerabile.
    Se il server centrale viene bloccato, tutti i bot non possono più
    ricevere comandi. Questo a sua volta è diviso in due categorie:
    \begin{itemize}
        \item \textbf{Internet Relay Chat (IRC)}: IRC è un sistema di chat
        usato per comunicare tra i bot e il botmaster in tempo reale.
        Questo era più usato nella prima generazione di botnet. 
        I bot si connettono al server IRC e aspettano
        i comandi dal botmaster. I bot seguono un approccio PUSH ovvero
        quando un bot si connette ad un determinato canale, esso rimane connesso.
        \item \textbf{HTTP / HTTPS}: Il più usato. Con questa tecnica, i bot usano un URL o IP
        per contatattare il server C\&C. Qua invece i bot seguono
        un approccio PULL. I bot si connettono al server C\&C
        periodicamente e controllano se ci sono nuovi comandi. Questo processo
        va ad intervalli regolari definiti dal botmaster.
    \end{itemize}

    \item \textbf{Decentralizzati}: Questo tipo di C\&C
    è basato su un sistema P2P senza un server centrale. In questo modo,
    computer infetti fanno sia da bot che da server.
    Questo metodo è più difficile da rilevare ma anche
    più complesso da implementare \cite{4804459}.

\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/Types-of-CC.png}
    \caption{Esempio di server C\&C. (a) centralizzato, (b) decentralizzato \cite{6487169}}
    \label{fig:command and control}
\end{figure}

\subsection{Domain Generation Algorithm}

I Domain Generation Algorithm (DGA) sono algoritmi che generano migliaia di domini in modo pseudo casuale.
Prima viene scelto un seed, che può essere la data odierna
o anche le previsioni meteo \cite{8621875} e, tramite
un algoritmo di hashing, vengono generati i domini.
Questi domini vengono poi utilizzati per contattare i server C\&C.
Non tutti i domini generati però sono registrati.
Il computer infetto, tramite i DNS locali, cercherà di tradurre
un dominio in un indirizzo IP.
Se esso non riesce a contattare il server con un determinato dominio,
proverà con il successivo finché non troverà
un dominio valido che permetterà al malware di comunicare con
il server C\&C \cite{8489147}.
In questo modo, diventa più difficile per i sistemi di protezione
rilevare e bloccare i loro attacchi.
Si potrebbe pensare di bloccare direttamente i domini tramite
una blacklist ma questo metodo
risulta inefficace poiché vengono generati migliaia di domini
continuamente. Si pensi che Conficker C, un famoso malware
che utilizza DGA, è in grado di generare
fino a 50.000 domini pseudo casuali al giorno \cite{978131}.
Un altro modo per contrastare ciò
potrebbe essere quello di fare reverse engineering
del DGA per capire quale seed viene utilizzato per generare i domini.
Questo però risulta lento e dispendioso e possibilmente inefficace \cite{8887881}.

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/DGA example.jpg}
    \caption{Esempio del funzionamento di un DGA \cite{8887881}}
    \label{fig:DGA example}
\end{figure}

Per contrastare i DGA, sono stati sviluppati
vari metodi di Machine Learning in grado di rilevare i domini generati.
Questi metodi hanno due lati poisitivi:
\begin{itemize}
    \item Non richiedono un lungo processo di reverse engineering.
    \item Essendo l'AI una blackbox, è molto difficile se non impossibile
    per gli hackers eseguire un reverse engineering del modello.
\end{itemize}

\section{Machine Learning}
Il machine learning è la branca dell'intelligenza artificiale che si occupa dello sviluppo
di algoritmi e tecniche finalizzate all'apprendimento automatico mediante
la statistica computazionale e l'ottimizzazione matematica.\cite{treccani2024}

\subsection{Sviluppo di un modello di Machine Learning}
Il primo passo per sviluppare un modello di Machine Learning è quello di
raccogliere i dati in un dataset. Nel nostro caso, dovendo riconoscere se un dominio
è lecito o DGA, il dataset conterrà
entrambi i tipi di domini che potranno avere o no un etichetta, DGA o legit nel nostro caso,
a seconda di come è strutturato il dataset possiamo avere vari tipi di allenamento:

\begin{itemize}
    \item \textbf{Supervised Learning}: È la tecnica più comune
    per allenare i modelli \cite{ayodele2010types}. In questo tipo di apprendimento,
    il modello viene addestrato su un dataset etichettato.
    \item \textbf{Unsupervised Learning}: In questo tipo di apprendimento,
    il modello, deve scoprire dei pattern o delle relazioni
    senza avere nessuna etichetta. Il modello deve trovare
    degli oggetti che condividono delle caratteristiche simili, chiamati
    cluster
    \item \textbf{Reinforcement Learning}: In questo tipo di apprendimento,
    ogni azione ha un effetto nell'ambiente che può essere positivo
    o negativo.
\end{itemize}

\noindent Si è soliti dividere il dataset in tre parti ovvero training set, validation set e test set.
Il \textbf{training set} è il dataset su cui viene addestrato
il modello, il \textbf{validation set} è una parte del training set
utile per riconoscere se il modello è in grado di generalizzare
su dati nuovi ovvero non va in overfitting o underfitting durante l'addestramento.
il \textbf{test set}, invece, è il dataset
su cui viene testata la precisione del modello.
Per la divisione del dataset non esiste una regola fissa,
ma solitamente il training set è più grande del validation set
e del test set. Un esempio potrebbe essere 90\% training set, 10\% validation set
e 10\% test set.
Successivamente vengono inizializzati i parametri del modello
che per un modello classico come il Random Forest
possono essere il numero di alberi o il numero di features da usare.
Per un modello di deep learning, invece, i parametri possono essere
il numero di epoche, il numero di batch e il numero di neuroni per ogni layer.
Un modello troppo semplice, con pochi alberi o pochi neuroni,
potrebbe non essere in grado di apprendere i pattern
nei dati (\textbf{Underfitting}), mentre al contrario,
una modello troppo complesso potrebbe imparare
troppo bene i dati e non generalizzare su dati nuovi
(\textbf{Overfitting}).
Dopo di che si passa alla fase vera e propria di addestramento.
Per un modello classico dipende dal tipo di algoritmo usato.
Per il random forest, ad esempio, viene creato un certo numero di alberi. ognuno con una parte casuale del training set
e viene calcolata la previsione di ogni albero.
Il risultato sarà la maggioranza delle previsioni degli alberi o la media qualora si tratti di un problema di regressione.
Per XGBoost, invece, viene creato un albero e
viene calcolato l'errore del modello e, successivamente, verrà creato un nuovo albero
che cercherà di correggere l'errore del modello precedente e questo fino a $n$ alberi.
Per i modelli di Deep Learning, invece, esso viene iterato per un certo numero di epoche su un batch di dati.
Il numero di \textbf{epoche} è un iperparametro, ovvero un parametro che non cambia durante l'addestramento, che indica quante volte
l'algoritmo di apprendimento deve passare attraverso il dataset di training\cite{brownlee2018difference}.
Un \textbf{batch} è un sottoinsieme del training set dopo il quale il modello
aggiorna i propri pesi. Ad esempio abbiamo un training set di 10000 dati
e un batch size di 100. Ogni 100 dati il modello calcolerà
l'output e la loss function, cioè la funzione che calcola
la differenza tra l'output previsto e quello reale, e aggiornerà i pesi di conseguenza.
Infine viene testato il modello sul test set e, se la precisione
è soddisfacente, il modello potrà essere usato.
\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/Machine-learning-pipeline.png}
    \caption{Pipeline di un modello di Machine Learning \cite{phdthesishamza}}
    \label{fig:ML pipeline}
\end{figure}

\subsection{Reti Neurali}

Una \textbf{Rete Neurale} o in inglese \textbf{Artificial Neural Network} (ANN) è
un modello matematico che mira a simulare il
funzionamento del cervello umano \cite{zou2009overview}.
Il cervello umano è composto da miliardi di neuroni
che comunicano tra di loro tramite sinapsi.
Con le reti neurali artificiali, il funzionamento
è analogo. A livello matematico, un neurone artificiale è composto principalmente
da due componenti:
\begin{itemize}
    \item \textbf{Pesi}: i pesi(weights in inglese) sono valori numerici che
    aiutano ogni nodo della rete neurale a determinare
    l'importanza di un input. Usando i pesi, il neurone
    può decidere se un input è importante o meno.
    \item \textbf{Funzione di attivazione}: la funzione di attivazione del neurone è la funzione
    che prende in input la sommatoria dei dati pesati con i pesi descritti in
    precedenza e produce un output che verrà poi inviato ad altri neuroni come
    input. Alcune delle funzioni di attivazione più comuni sono la funzione
    sigmoide e la funzione ReLU.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/ArtificialNeuronModel.png}
    \caption{Esempio di neurone artificiale \cite{wiki:xxx}}
    \label{fig:AN}
\end{figure}

A sua volta una rete neurale è composta da vari strati:
\begin{itemize}
    \item \textbf{Input Layer}: il primo strato della rete neurale
    e quello che riceve l'input esterno. Poiché la rete neurale
    è un modello matematico, l'input dovrà essere
    un vettore numerico. Questo vale anche se l'input da esaminare
    è una stringa di caratteri. In questo caso, quindi, la stringa va convertita in un vettore numerico
    come vedremo in seguito.
    \item \textbf{Hidden Layer}: questo è lo strato intermedio della rete neurale in cui avviene
    il processo di apprendimento.
    Questo strato elabora gli input ricevuti dallo strato precedente
    modificando i pesi. Si possono avere anche più hidden layers
    \item \textbf{Output Layer}: Questo è l'ultimo strato della rete neurale.
    Fornisce i risultati finali ottenuti dalla rete neurale. Questo strato
    può essere composto anche da un solo neurone che fornisce
    un output binario (0 o 1) come sarà nel nostro caso(DGA o legit)
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/MultiLayerNeuralNetwork.png}
    \caption{Esempio di rete neurale \cite{wiki:001}}
    \label{fig:ANN}
\end{figure}

Abbiamo inoltre vari tipi di reti neurali:
\begin{itemize}
    \item \textbf{Reti Neurali Feedforward(FNN)}: Una rete Feedforward
    elabora le informazioni in un solo verso. Non ha né cicli
    né memoria delle informazioni passate. Questo tipo di rete
    è usato ad esempio per il riconoscimento di pattern.
    \item \textbf{Reti Neurali Ricorrenti (RNN)}:
    A differenza di una rete Feedforward, in una RNN 
    i neuroni possono andare anche a formare dei cicli. 
    Questo permette alla rete di avere una specie di memoria
    e quindi di ricordare le informazioni passate. Usata
    per esempio per traduzione automatica o riconoscimento vocale.
    \item \textbf{Reti Neurali Convoluzionali (CNN)}: Questo tipo di rete
    è usato principalmente per dati strutturati a griglia ad esempio le immagini.
    Il nome "Convoluzionali" deriva dal fatto che la
    rete usa un'operazione matematica chiamata proprio
    convoluzione. Le CNN sono usate soprattuto nell'ambito della
    visione artificiale per il riconoscimento di oggetti
    \cite{Goodfellow-et-al-2016}.
\end{itemize}

\section{Algoritmi di Machine Learning adatti per DGA}

Ora che abbiamo visto i concetti di base del Machine Learning, delle reti neurali
e dei DGA, vediamo alcuni degli algoritmi che possono essere usati
per rilevare i domini generati da DGA.

\subsection{Random Forest}

Random Forest è un algoritmo esamble (cioè unisce più modelli) di Machine Learning supervisionato
che usa un insieme di alberi decisionali
per classificare i dati. Un albero decisionale è un modello che usa appunto una struttura ad albero
per prendere decisioni. Un esempio può essere quello nella \cref{fig:decision tree}, in cui, a seconda di determinate
caratteristiche, l'albero decide se una persona rischia di avere un attacco cardiaco o meno.
Il problema principale del singolo albero decisionale è che è molto suscettibile
all'overfitting.
\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/Decision_tree_for_heart_attack.png}
    \caption{Esempio di albero decisionale \cite{decision_tree_image}}
    \label{fig:decision tree}
\end{figure}

\noindent Il random forest risolve questo problema aumentando 
l'accuratezza del modello sia in fase di training che in fase di testing. \cite{598994}
Esso usa un apporccio basato su feature, ovvero vengono selezionate
delle caratteristiche del dataset che possono essere utili per la classificazione.
Ad esempio, nel nostro caso, le caratteristiche potrebbero essere
il numero di vocali, lunghezza del dominio o l'entropia.
L'algoritmo funziona nel seguente modo:
Per prima cosa vengono creati $n$ alberi decisionali, ognuno
contenente una parte casuale del training set. Inoltre
ogni albero decisionale viene addestrato su un sottoinsieme casuale
di feature. Dopo di che, ogni albero fa la sua previsione,
e la previsione finale viene fatta in base a ciò che la maggior parte
degli alberi ha previsto se si tratta di un problema di classificazione mentre, qualora si trattasse di un problema di regressione,
la previsione finale sarà la media delle previsioni di tutti gli alberi.
Questa tecnica è chiamata \textbf{Bagging} o Bootstrap Aggregating.

\begin{figure}
    \centering
    \includegraphics[width=.8\linewidth]{figures/Illustration-of-random-forest-trees.jpg}
    \caption{Esempio di Random Forest \cite{RFIMAGE}}
    \label{fig:random forest}
\end{figure}



\subsection{XGBoost}
XGBoost, abbreviazione di eXtreme Gradient Boosting, è un algoritmo di Machine Learning
esamble che combina più alberi decisionali come il Random Forest.
La differenza principale tra i due algoritmi è che XGBoost usa un approccio
\textbf{Boosting} invece che Bagging.
Il Boosting è un metodo che combina più modelli
messi in sequenza, in modo che ogni modello successivo
cerchi di correggere gli errori del modello precedente.
Il Boosting funziona nel seguente modo:
\begin{enumerate}
    \item Viene creato un albero decisionale e viene allenato sui dati.
    \item Viene calcolato quante predizioni sono state sbagliate
    \item Viene creato un nuovo albero decisionale che verrà addestrato sugli errori del modello precedente.
    \item Si ripete il processo fino a quando non verrà soddisfatto un criterio di stop.
\end{enumerate}

\noindent La differenza tra il boosting standard e XGBoost è che quest'ultimo
risulta più performante e meno soggetto all'overfitting
grazie all'uso di tecniche di regolarizzazione come il L1 e L2 regularization
e la parallelizzazione del processo di addestramento \cite{Xgboost2016}

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/XGBoost_structure.png}
    \caption{Esempio di XGBoost \cite{Xgboostimage}}
    \label{fig:XGBoost}
\end{figure}


\subsection{Long Short Term Memory (LSTM)}

Le LSTM sono un tipo di rete neurale ricorrente (RNN). 
A differenza delle RNN tradizionali, esse sono in grado di
memorizzare informazioni per periodi di tempo più lunghi e possono
avere più strati nascosti. Create da Hochreiter e Schmidhuber nel 1997 \cite{LSTM1997},
le LSTM risolvono uno dei problemi più importanti
delle RNN standard, il vanishing gradient problem. Questo
problema si verifica poiché durante la backpropagation, i gradienti
tendono appunto a svanire, rendendo difficile l'apprendimento
di relazioni a lungo termine. 
Per risolverlo, le LSTM introducono una struttura dati vettoriale
chiamata \textbf{Memory Cell}(o cella di memoria). Questa viene
viene aggiornata ad ogni step tramite le operazioni decise dai "gates" (o porte).
La struttura delle LSTM è composta nel seguente modo:
\begin{itemize}
    \item \textbf{Input Gate}: determina quali nuove informazioni
    devono essere aggiunte allo stato della cella. Usa una funzione
    sigmoide per decidere quali valori saranno aggiunti e una tanh
    per creare nuovi valori
    \item \textbf{Forget Gate}: gestisce quali informazioni
    devono essere dimenticate dallo stato della cella. Usa una funzione
    sigmoide per decidere quali informazioni saranno mantenute o dimenticate.
    Se il valore è 0 le informazioni saranno dimenticate mentre se è 1 saranno mantenute.
    \item \textbf{Output Gate}: decide come sarà il prossimo hidden state
    Gli input sono passati a una funzione sigmoide e la cella
    aggiornata viene passata a una tanh e moltiplicata con l'output della sigmoide
    per decidere quali informazioni saranno passate.
\end{itemize}

\noindent Oltre alle LSTM tradizionali abbiamo anche le \textbf{BLSTM} (Bidirectional LSTM) che sono
composte da due LSTM, che elaborano i dati in due direzioni diverse.
A differenza del Random Forest e del XGBoost, le LSTM usano un approccio featureless e imparano
direttamente dai dati.

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/gate_of_lstm.png}
    \caption{Struttura di un LSTM \cite{LSTM_image}}
    \label{fig:LSTM}
\end{figure}


\chapter{Progetto}
Il progetto ha come obiettivo quello di sviluppare un sistema
di rilevamento di domini generati da DGA tramite
l'uso di tecniche di Machine Learning. 
Per il dataset ho deciso di usare il dataset di YangYang \cite{dataset_yangyang}
che contiene circa 1.5 milioni di domini DGA e circa 1.5 milioni di domini legittimi.

\section{Linguaggi e librerie usate}
Per il progetto è stato usato il linguaggio Python poiché è il più usato
in ambito Machine Learning e analisi dei dati e offre una vasta gamma di librerie
adatte a questo scopo. Le librerie usate sono:
\begin{itemize}
    \item \textbf{Pandas}: libreria per la manipolazione e l'analisi dei dati.
    \item \textbf{Numpy}: libreria per il calcolo scientifico e l'elaborazione di array.
    \item \textbf{math}: libreria per le funzioni matematiche di base.
    \item \textbf{Scikit-learn}: libreria per il Machine Learning che offre vari algoritmi
    e strumenti per la valutazione dei modelli. Nel nostro caso è stata usata per 
    la divisione del dataset in training, validation e test set,
    per l'implementazione del modello Random Forest e per il calcolo delle metriche di valutazione.
    \item \textbf{XGBoost}: libreria per l'implementazione dell'algoritmo XGBoost.
    \item \textbf{Tensorflow e Keras}: librerie per la creazione di reti neurali. Un tempo erano due librerie
    separate ma dal 2017 Keras è parte integrante di Tensorflow. 
    Usate per la tokenization dei domini e per l'implementazione delle LSTM e BLSTM.
    \item \textbf{Matplotlib}: libreria per la visualizzazione dei dati e per la creazione di grafici.
\end{itemize}

\section{Metriche di valutazione}
Per valutare le prestazioni dei vari modelli si è deciso di usare i seguenti
parametri:
Accuracy, Pecision, Recall, F1-Score e Confusion Matrix. \hfill \break
L'\textbf{Accuracy} è il rapporto del numero di predizioni
corrette sul numero totale di predizioni effettuate.
La formula è la seguente:
\begin{equation}
    Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}

dove:
\begin{itemize}
    \item $TP$ è il numero di True Positive (Il numero di DGA classificati correttamente)
    \item $TN$ è il numero di True Negative (Il numero di domini legittimi classificati correttamente)
    \item $FP$ è il numero di False Positive (Il numero di domini legittimi classificati come DGA)
    \item $FN$ è il numero di False Negative (Il numero di DGA classificati come domini legittimi)
\end{itemize}

\noindent La \textbf{Precision} è il rapporto tra il numero di True Positive 
e il numero totale di predizioni positive effettuate.
La formula è la seguente:
\begin{equation}
    Precision = \frac{TP}{TP + FP}
\end{equation}
La \textbf{Recall} è il rapporto tra il numero di True Positive
e il numero totale di positivi ed è definita come segue:
\begin{equation}
    Recall = \frac{TP}{TP + FN}
\end{equation}
L'\textbf{F1-Score} è la media armonica tra Precision e Recall.
ed è definita come:
\begin{equation}
    F1-Score = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}
\end{equation}
Nel progetto è stata usato Classification Report di scikit-learn
per calcolare queste metriche.
La \textbf{Confusion Matrix} è una matrice che mostra il numero di predizioni
corrette e sbagliate per ogni classe. Un vantaggio
della Confusion Matrix è che permette di vedere
quali classi sono state classificate correttamente e quali no e la quantità precisa di ogni classe.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{figures/confusion-matrix.png}
    \caption{Esempio di Confusion Matrix \cite{confusion_matrix_image}}
    \label{fig:confusion matrix}
\end{figure}

\section{Progettazione con Random Forest}

Il primo algoritmo testato è stato il Random Forest.
Per implementarlo si è usata la classe \texttt{RandomForestClassifier} della libreria
\texttt{scikit-learn} \cite{scikit_learn_rf}.
Qui non abbiamo bisogno di convertire i domini in
altri formati poiché il modello prenderà
come dati non il dominio in sé ma le sue caratteristiche(o features).
I parametri che prende il modello sono:
\begin{itemize}
    \item \textbf{n\_estimators}: il numero di alberi decisionali da creare
    Di default è 100. Si è provato ad aumentare il valore finchè, a parte un maggiore
    tempo di addestramento, non si è notato alcun miglioramento significativo.
    Alla fine si è deciso di usare il valore 200.
    \item \textbf{criterion}: la funzione usata per misurare la qualità di una divisione.
    Di default usa la funzione "gini".
    \item \textbf{max\_depth}: la profondità massima di ogni albero.
    Di default è None, ovvero gli alberi cresceranno fino a quando
    tutti i nodi saranno puri o fino a quando tutte le foglie
    conterranno meno di min\_samples\_split campioni.
    \item \textbf{min\_samples\_split}: il numero minimo di campioni richiesti
    per dividere un nodo interno. Di default è 2.
    \item \textbf{min\_samples\_leaf}: il numero minimo di campioni richiesti
    per essere una foglia. Di default è 1.
    \item \textbf{max\_features}: il numero massimo di feature da considerare
    per la divisione di un nodo. Di default è "sqrt" ovvero la radice quadrata
    del numero di feature.
    \item \textbf{n\_jobs}: il numero di processi paralleli da usare per l'addestramento.
    Di default è 1, ma si può impostare a -1 per usare tutti i processi disponibili, 
    aumentando così la velocità di addestramento.
    \item \textbf{random\_state}: il seed per la generazione casuale dei dati.
    Di default è None, ma facendo così il modello resituirà risultati diversi.
    Perciò si è deciso di dargli un seed fisso.
\end{itemize}
A parte per il random\_state, il numero di alberi e n\_jobs, gli altri parametri sono stati lasciati
con i valori di default poiché, dopo vari test non sono stati riscontrati grossi miglioramenti.
Inizialmente sono state usate come features la lunghezza del dominio, il numero di vocali,
il numero di consonanti, la quantità di numeri e l'entropia del dominio.
L'entropia misura la randomicità di una stringa e viene calcolata con la seguente formula:
\begin{equation}
    Entropy = -\sum_{i=1}^{n} p_i \cdot \log_2(p_i)
\end{equation}
dove $p_i$ è la probabilità di ogni carattere nel dominio. \hfil \break
Successivamente sono stati aggiunte altre features come il ratio tra consonanti e vocali,
il numero di trattini, l'entropia per bigramma, e il numero di consonanti e vocali consecutive.
\texttt{RandomForestClassifier}, inoltre, possiede un attributo che permette di calcolare l'importanza di ogni feature nel modello
chiamato \texttt{feature\_importances\_}\footnote{In scikit-learn i metodi con il suffisso "\_" sono attributi che possono essere calcolati solo dopo l'addestramento del modello \cite{scikit_learn_underscore}}.
Grazie ad esso si è notato che le features più importanti sono state
l'entropia e quante vocali consecutive ci sono nel dominio.
Alcune features come se il dominio contiene un numero all'inizio o alla fine
o se il dominio contiene una wordlist di parole comuni ai DGA sono state
rimosse poiché non portavano un miglioramento significativo e anzi 
rischiavano di portare a un overfitting del modello.
\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/RF_feature.png}
    \caption{Parte del dataset con i domini e loro features}
    \label{fig:RF feature}
\end{figure}

\subsection{Test con Random Forest}
Il modello ha impiegato circa 10 minuti per l'addestramento e, dopo vari test,
si è raggiunta un accuratezza del 91\% ma
con risultati peggiori nel riconoscimento dei DGA rispetto ai legit come si può vedere nella \cref{fig:RF results}.

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/RF_results.png}
    \caption{Risultati del modello Random Forest}
    \label{fig:RF results}
\end{figure}

\noindent Dalla Confusion Matrix \ref{fig:RF confusion matrix} si può vedere che il modello ha classificato
più di 5000 False Negative ovvero domini DGA classificati come legittimi rispetto ai False Positive.

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/RF_conf_matr.png}
    \caption{Confusion Matrix del modello Random Forest}
    \label{fig:RF confusion matrix}
\end{figure}

\section{Progettazione con XGBoost}
XGBoost come Random Forest non ha bisogno dei dati convertiti in vettori numerici
ma delle loro features.
Per implementarlo si è usata l'omonima libreria \texttt{XGBoost} \cite{xgboost_cl}.
Le features usate sono state le stesse del modello Random Forest poiché,
anche in questo caso, alcune features non davano miglioramenti o rischiavano
di portare anche ad un overfitting del modello.
I parametri che XGBoost prende in input sono:
\begin{itemize}
    \item \textbf{n\_estimators}: il numero di alberi da creare.
    Di default è 100. Essendo un modello sequenziale, il numero di alberi
    può essere aumentato di molto e aggiungere un early stopping
    per evitare l'overfitting. L'early stopping è un metodo che interrompe
    l'addestramento quando il modello non migliora più. Il numero
    di alberi che si è scelto è 10000.
    \item \textbf{learning\_rate}: il tasso di apprendimento del modello.
    Di default è 0.3. Questo parametro controlla quanto il modello
    impara ad ogni iterazione. Un valore più basso può portare a un modello
    più preciso ma richiede più iterazioni.
    Si è provato inizialmente il valore di default e progressivamente
    è stato abbassato fino a 0.01.
    \item \textbf{max\_depth}: la profondità massima di ogni albero.
    Di default è 6. Più si aumenta questo valore, più il modello
    diventa complesso e rischia di andare in overfitting.
    Si è deciso di usare il valore di default.
    \item \textbf{min\_child\_weight}: il peso minimo di un nodo figlio.
    Di default è 1. Questo parametro controlla la quantità minima
    di campioni richiesti per creare un nodo figlio. Un valore più alto
    può portare a un modello più semplice e meno suscettibile all'overfitting
    ma se troppo alto esso può portare ad underfitting.
    Si è deciso di usare 3.
    \item \textbf{subsample}: la frazione di campioni da usare per addestrare
    ogni albero che deve essere compresa tra 0 e 1. Di default è 1
    si è scelto di usare 0.85.
    \item \textbf{colsample\_bytree}: la frazione di feature da usare per addestrare
    ogni albero che deve essere compresa tra 0 e 1. Di default è 1.
    Si è deciso di usare 0.85 anche qui.
    \item \textbf{gamma}: il valore minimo di perdita richiesta per fare una divisione.
    Di default è 0 e si è deciso di lasciarlo così.
    \item \textbf{reg\_alpha}: il termine di regolarizzazione L1 da applicare.
    più alto è il valore, più il modello sarà semplice e meno suscettibile all'overfitting.
    Di default è 0 e si è deciso di usare 0.1.
    \item \textbf{reg\_lambda}: il termine di regolarizzazione L2 da applicare.
    Come per reg\_alpha, più alto è il valore, più il modello sarà semplice.
    Di default è 1 e si è lasciato così.
    \item \textbf{random\_state}: il seed per la generazione casuale dei dati.
    \item \textbf{eta}: il tasso di apprendimento del modello.
    Di default è 0.3. Dopo vari test
    non si è notato alcun miglioramento perciò 
    si è deciso di usare il valore di default.
\end{itemize}

\noindent Inizialmente si è addestrato il modello con i setting base, impiegando circa 7 minuti. 
Successivamente avendo notato che il modello
poteva essere addestrato anche con la GPU e supportando la parallelizzazione, si è deciso di usarla
e i tempi di addestramento sono scesi drasticamente,
impiegando all'incirca 1 minuto per un addestramento completo.

\subsection{Test con XGBoost}
I risultati sono leggermente migliori rispetto al modello Random Forest
con un accuretezza di quasi il 93\%. L'F1-Score, come per il Random Forest,
risulta maggiore per i domini legit,
con uno 0.92 per i domini DGA e 0.93 per i domini legittimi,
come si può vedere nella \cref{fig:XGBoost results}.
\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/XGBoost_results.png}
    \caption{Risultati del modello XGBoost}
    \label{fig:XGBoost results}
\end{figure}

\noindent Dalla Confusion Matrix \ref{fig:XGBoost confusion matrix} si può vedere che il modello ha classificato
il 3\% in più di false negative rispetto ai false positive.
\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/XGBoost_conf_matr.png}
    \caption{Confusion Matrix del modello XGBoost}
    \label{fig:XGBoost confusion matrix}
\end{figure}


\section{Progettazione LSTM}
Poiché LSTM è adatto anche per il riconoscimento di pattern
si è deciso di usarlo per il progetto sia nella sua forma classica che in quella bidirezionale.
Per implementare le LSTM sia classiche che BLSTM si è usata la libreria \texttt{Keras} \cite{Keras}
ora parte di Tensorflow
e la sua classe \texttt{LSTM} per le LSTM classiche e \texttt{Bidirectional} per le BLSTM.
A differenza dei modelli di Machine Learning precedenti,
le LSTM non hanno bisogno delle features poiché esse imparano direttamente dai dati.
Il modello però non è in grado di leggere direttamente i domini.
Perciò bisogna convertire i domini in un formato leggibile dalla rete neurale e questo viene
svolto tramite un processo chiamato \textbf{Tokenization}.
Questo converte i dati in un formato leggibile dalla rete neurale.
Ci sono vari metodi di tokenization come word tokenization, che divide 
le stringhe in più parole o la character tokenization
che divide le stringhe in singoli caratteri. Essendo i domini delle semplici stringhe,
spesso senza parole di senso compiuto e con caratteri speciali come il punto o il trattino,
per questo progetto si è deciso di usare la character tokenization.
Per fare ciò si è usato il metodo \texttt{Tokenizer} di Keras.
Si è deciso di usare
un modello sequenziale, in cui gli
strati sono disposti in sequenza uno dopo l'altro. \hfil \break
Il primo è uno strato di embedding che serve 
a convertire i caratteri in vettori numerici poiché,
come detto in precedenza, le reti neurali
possono leggere solo numeri. \hfil \break
Successivamente nel modello è presente uno strato di LSTM
con 128 neuroni. Il numero di neuroni non 
è un valore fisso e non è determinato da una regola precisa.
Esso può essere scelto in base
alla complessità del problema o alla quantità di dati
presenti nel dataset. In generale con troppi neuroni si rischia di
andare in overfitting e con pochi il contrario. Dopo
vari tentativi, 128 neuroni è sembrata la scelta migliore poiché
con più neuroni il modello non imparava, rimanendo bloccato con un accuracy di 0.5(50\%) circa. \hfil \break
Dopo di che è stato aggiunto uno strato di dropout,
ovvero uno strato che disabilita casualmente
un certo numero di neuroni durante l'addestramento 
per evitare l'overfitting, con un rate di 0.2. Anche il rate di dropout non
è un valore fisso.
Dopo è presente un altro strato LSTM come il primo e un dropout
e uno strato con attivazione relu con 64 neuroni che serve
a catturare pattern più complessi. Inizialmente
si era provato senza questo strato ma 
il modello aveva una precisione inferiore di circa il 5\% mentre con lo stesso
strato con 128 neuroni il modello aveva la stessa precisione e F1-Score ma con tempi
di addestramento maggiori. Infine
l'ultimo è uno strato denso con attivazione sigmoide
che serve a classificare i dati in due classi, DGA e non DGA.
Per incrementare ulteriormente la precisione del modello,
è stato utilizzato anche il metodo \texttt{ReduceLROnPlateau} di Keras.
Questo metodo riduce il learning rate appena il modello non migliora più
permettendo una migliore convergenza \footnote{In ambito Machine Learning, un modello converge quando esso non può migliorare più di così anche con un ulteriore allenamento\cite{convergence}}. Nel nostro caso
la patience, ovvero il numero di epoche prima di ridurre il learning rate,
è stato impostato a 2 mentre il fattore di riduzione è 0.5.
Per compilare il modello si è usato l'ottimizzatore Adam,
poiché è risultato il migliore in termini di velocità e precisione.
Per il training sono state scelte inizialmente 5 e poi 10 epoch.
Il modello però non riusciva a generalizzare, quindi si è deciso di aumentare
il numero di epoche a 50 e di usare l'early stopping, un metodo per interrompere
l'addestramento quando il modello non migliora più. La patience in questo
caso è stata impostata a 3. Alla
fine l'addestramento si è fermato all'epoch 26 impiegando circa 30 minuti e poco più di 1 minuto per epoca.

\subsection{Test con LSTM}
Il modello raggiunge il 99\% di accuracy e un alto F1-Score nel riconoscimento di entrambi i tipi di domini,
come si può vedere nella \cref{fig:LSTM results}.

\begin{figure}[h]
    \centering
    \includegraphics[width=.8\linewidth]{figures/LSTM_results.png}
    \caption{Risultati del modello LSTM}
    \label{fig:LSTM results}
\end{figure}

\noindent Dalla confusion matrix \ref{fig:LSTM confusion matrix} si può vedere che il modello ha classificato quasi tutti 
i domini correttamente. Leggermente di più sono i
False Negative ovvero domini DGA classificati come legittimi.
\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/LSTM conf_matr.png}
    \caption{Confusion Matrix del modello LSTM}
    \label{fig:LSTM confusion matrix}
\end{figure}

\section{Progettazione BLSTM}

Come detto in precedenza, le BLSTM sono una variante delle LSTM che
consentono di elaborare i dati in entrambe le direzioni.
Questo permette al modello di catturare meglio
i pattern nei dati.
Come nelle LSTM aumentare o dimunire il numero di neuroni
non ha avuto effetti positivi sul modello perciò si è deciso di usare anche qui
128 neuroni per ogni strato BLSTM, gli strati di dropout, e uno denso con attivazione relu con 64 neuroni.
Le epoche scelte sono anche qui 50 con early stopping con patience settata a 3.
Le tempistiche di addestramento, però, sono risultate di gran lunga
maggiori rispetto alle LSTM classiche.
Per migliorare i tempi di addestramento si è deciso di usare il metodo \texttt{mixed\_precision\_policy} di Keras
con \texttt{mixed\_float16} come paramentro. Questo permette di usare
la precisione a 16 bit per i pesi e le attivazioni
e la precisione a 32 bit per i gradienti e le perdite riducendo i tempi di addestramento.
Alla fine il modello ha impiegato circa 4 minuti ad epoca e circa 1 ora e 10 minuti per 22 epochs totali.

\subsection{Test con BLSTM}
I risultati sono stati molto simili a quelli delle LSTM come si può vedere nella \cref{fig:BLSTM results}.

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/BLSTM_results.png}
    \caption{Risultati del modello BLSTM}
    \label{fig:BLSTM results}
\end{figure}

\noindent Per quanto riguarda la confusion matrix \ref{fig:BLSTM confusion matrix}, il modello ha classificato
quasi tutti i domini correttamente. Il modello risulta più preciso anche se di poco rispetto alle LSTM classiche.
La maggior parte degli errori sono False Negative anche qui
\begin{figure}[H]
    \centering
    \includegraphics[width=.8\linewidth]{figures/BLSTM conf_matr.png}
    \caption{Confusion Matrix del modello BLSTM}
    \label{fig:BLSTM confusion matrix}
\end{figure}

\chapter{Conclusioni e sviluppi futuri}
In questo progetto di tesi sono stati analizzati e sviluppati
vari modelli di Machine Learning per il riconoscimento
di domini generati da DGA.
Il risultato migliore è stato ottenuto con i modelli basati sul 
Deep Learning, ovvero le LSTM e le BLSTM,
che hanno raggiunto un'accuratezza del 99\% e un F1-Score
di 0.99 per entrambi i tipi di domini.
I modelli di Machine Learning basati su Feature Extraction, come il Random Forest e XGBoost,
hanno raggiunto un'accuratezza del 91\% e 93\% rispettivamente
quindi dimostrandosi meno precisi ma allo stesso tempo
più veloci nell'addestramento e nell'esecuzione.
Il progetto ha dimostrato che le reti neurali ricorrenti
sono adatte per il riconoscimento di pattern nei dati.

% \chapter{Contribution}

% You may also put some code snippet (which is NOT float by default), eg: \cref{lst:random-code}.

% \lstinputlisting[float,language=Java,label={lst:random-code}]{listings/HelloWorld.java}

% \section{Fancy formulas here}


%----------------------------------------------------------------------------------------
% BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\backmatter
\cleardoublepage
\phantomsection
\bibliographystyle{IEEEtran} %prima era alpha
\bibliography{bibliography}

% \begin{acknowledgements} % this is optional
%  Optional. Max 1 page.
% \end{acknowledgements}

\chapter*{Ringraziamenti}
\markboth{RINGRAZIAMENTI}{RINGRAZIAMENTI}
Con questo lavoro di tesi, si conclude il mio percorso di studi
sicuramente non facile ma che mi ha dato la possibilità di crescere sia
a livello personale che professionale.  \hfill \break
Ringrazio il mio relatore, il Prof. Mirko Viroli per essere stato sempre disponibile e avermi aiutato con il lavoro
e Lorenzo Magi e tutta Flashstart per l'aiuto dato e per avermi dato la possibilità di lavorare su questo progetto.  \hfill \break
Ringrazio la mia famiglia per avermi sempre supportato sia moralmente che economicamente. Senza
di loro non sarei mai riuscito a raggiungere questo traguardo.  \hfill \break
Ringrazio i miei amici in particolare l'associazione Sprite che hanno
reso questo percorso più divertente.
Ringrazio i bloccati e gli amici di Smash Bros per i momenti di divertimento e avermi dato un hobby per
staccare dallo studio.


\end{document}
